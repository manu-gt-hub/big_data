version: '2'
services:

  hadoop:
    hostname: hadoop
    container_name: insert_hadoop
    image: insert_hadoop
    container_name: hadoop
    ports:
      - "50070:50070"
      - "8020:8020"
      - "50075:50075"

  spark-master:
    image: bde2020/spark-master:2.3.2-hadoop2.7
    container_name: insert_spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark

  spark-worker-1:
    image: bde2020/spark-worker:2.3.2-hadoop2.7
    container_name: insert_spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"

  spark-worker-2:
    image: bde2020/spark-worker:2.3.2-hadoop2.7
    container_name: insert_spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8082"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"

  mongodb:
    image: triply/mongodb:3.2.0-1
    environment:
      - USERMAP_GID=1000
      - USERMAP_UID=1000
    ports:
      - "27017:27017"
    volumes:
      - db:/data/db

  elasticsearch:
    image: 'elasticsearch:6.4.2'
    container_name: insert_elasticsearch
    hostname: elasticsearch
    privileged: true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"

volumes:
  db:
    driver: local